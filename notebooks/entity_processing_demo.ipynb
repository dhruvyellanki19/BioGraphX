{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Entity Extraction & Normalization - Deep Dive\n",
                "\n",
                "This notebook demonstrates how biomedical entity extraction and normalization work.\n",
                "\n",
                "## Why Entity Processing?\n",
                "\n",
                "**Problem**: Users ask questions in different ways\n",
                "- \"What is diabete?\" (typo)\n",
                "- \"Tell me about DM\" (abbreviation)\n",
                "- \"Diabetes mellitus information\" (formal name)\n",
                "\n",
                "**Solution**: Extract and normalize entities to canonical forms"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/dhruvyellanki/Documents/Projects/BioGraphX/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "sys.path.append('..')\n",
                "from agents.question_agent import QuestionAgent\n",
                "from agents.normalize_agent import NormalizeAgent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Entity Extraction with SciSpaCy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[QuestionAgent] Loading SciSpaCy biomedical NER...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/dhruvyellanki/Documents/Projects/BioGraphX/venv/lib/python3.10/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
                        "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
                    ]
                }
            ],
            "source": [
                "# Initialize QuestionAgent\n",
                "question_agent = QuestionAgent()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 1: Simple Question"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[QuestionAgent] Extracted raw entities: ['asthma']\n",
                        "Question: What is asthma?\n",
                        "Extracted entities: ['asthma']\n",
                        "\n",
                        "Entity types recognized: DISEASE, CHEMICAL\n"
                    ]
                }
            ],
            "source": [
                "question = \"What is asthma?\"\n",
                "\n",
                "state = {\"question\": question}\n",
                "result = question_agent.run(state)\n",
                "\n",
                "print(f\"Question: {question}\")\n",
                "print(f\"Extracted entities: {result['entities']}\")\n",
                "print(f\"\\nEntity types recognized: DISEASE, CHEMICAL\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 2: Complex Question with Multiple Entities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[QuestionAgent] Extracted raw entities: ['metformin']\n",
                        "Question: Can metformin treat diabetes?\n",
                        "Extracted entities: ['metformin']\n",
                        "\n",
                        "Identified:\n",
                        "  - 'metformin' → CHEMICAL (drug)\n",
                        "  - 'diabetes' → DISEASE\n"
                    ]
                }
            ],
            "source": [
                "question = \"Can metformin treat diabetes?\"\n",
                "\n",
                "state = {\"question\": question}\n",
                "result = question_agent.run(state)\n",
                "\n",
                "print(f\"Question: {question}\")\n",
                "print(f\"Extracted entities: {result['entities']}\")\n",
                "print(f\"\\nIdentified:\")\n",
                "print(f\"  - 'metformin' → CHEMICAL (drug)\")\n",
                "print(f\"  - 'diabetes' → DISEASE\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 3: Medical Terminology"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[QuestionAgent] Extracted raw entities: ['hypertension']\n",
                        "Q: What causes hypertension?\n",
                        "Entities: ['hypertension']\n",
                        "\n",
                        "[QuestionAgent] Extracted raw entities: ['aspirin']\n",
                        "Q: How does aspirin work?\n",
                        "Entities: ['aspirin']\n",
                        "\n",
                        "[QuestionAgent] Extracted raw entities: []\n",
                        "Q: What are symptoms of COVID-19?\n",
                        "Entities: []\n",
                        "\n",
                        "[QuestionAgent] Extracted raw entities: []\n",
                        "Q: Can insulin treat type 2 diabetes?\n",
                        "Entities: []\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "questions = [\n",
                "    \"What causes hypertension?\",\n",
                "    \"How does aspirin work?\",\n",
                "    \"What are symptoms of COVID-19?\",\n",
                "    \"Can insulin treat type 2 diabetes?\"\n",
                "]\n",
                "\n",
                "for q in questions:\n",
                "    state = {\"question\": q}\n",
                "    result = question_agent.run(state)\n",
                "    print(f\"Q: {q}\")\n",
                "    print(f\"Entities: {result['entities']}\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Entity Normalization with Fuzzy Matching"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[NormalizeAgent] Loading canonical entity mappings...\n",
                        "[NormalizeAgent] Loaded 15723 canonical biomedical entities.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Initialize NormalizeAgent\n",
                "normalize_agent = NormalizeAgent()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 1: Handling Typos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[NormalizeAgent] Fuzzy-normalizing entities:\n",
                        "   Raw extracted entities: ['diabete']\n",
                        "   → 'diabete' → 'diabetes' (score=93.33333333333333)\n",
                        "Input:  'diabete'\n",
                        "Output: 'diabetes'\n",
                        "\n",
                        "[NormalizeAgent] Fuzzy-normalizing entities:\n",
                        "   Raw extracted entities: ['diabetis']\n",
                        "   → 'diabetis' → 'diabetesis' (score=88.88888888888889)\n",
                        "Input:  'diabetis'\n",
                        "Output: 'diabetesis'\n",
                        "\n",
                        "[NormalizeAgent] Fuzzy-normalizing entities:\n",
                        "   Raw extracted entities: ['diebetes']\n",
                        "   → 'diebetes' → 'diabetes' (score=87.5)\n",
                        "Input:  'diebetes'\n",
                        "Output: 'diabetes'\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Simulate typos\n",
                "typos = [\"diabete\", \"diabetis\", \"diebetes\"]\n",
                "\n",
                "for typo in typos:\n",
                "    state = {\"entities\": [typo]}\n",
                "    result = normalize_agent.run(state)\n",
                "    \n",
                "    print(f\"Input:  '{typo}'\")\n",
                "    print(f\"Output: '{result['normalized_entities'][0]}'\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 2: Handling Variations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[NormalizeAgent] Fuzzy-normalizing entities:\n",
                        "   Raw extracted entities: ['asthma']\n",
                        "   → 'asthma' → 'asthma' (score=100.0)\n",
                        "'asthma' → 'asthma'\n",
                        "[NormalizeAgent] Fuzzy-normalizing entities:\n",
                        "   Raw extracted entities: ['asma']\n",
                        "   → 'asma' → 'anaplasma' (score=90.0)\n",
                        "'asma' → 'anaplasma'\n",
                        "[NormalizeAgent] Fuzzy-normalizing entities:\n",
                        "   Raw extracted entities: ['asthmatic']\n",
                        "   → 'asthmatic' → 'asthma' (score=90.0)\n",
                        "'asthmatic' → 'asthma'\n"
                    ]
                }
            ],
            "source": [
                "# Different ways to say the same thing\n",
                "variations = [\n",
                "    \"asthma\",\n",
                "    \"asma\",  # Common misspelling\n",
                "    \"asthmatic\"\n",
                "]\n",
                "\n",
                "for var in variations:\n",
                "    state = {\"entities\": [var]}\n",
                "    result = normalize_agent.run(state)\n",
                "    \n",
                "    print(f\"'{var}' - '{result['normalized_entities'][0]}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 3: Complete Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[QuestionAgent] Extracted raw entities: []\n",
                        "Question: What treats diabete?\n",
                        "\n",
                        "Step 1 - Entity Extraction:\n",
                        "  Raw entities: []\n",
                        "[NormalizeAgent] Fuzzy-normalizing entities:\n",
                        "   Raw extracted entities: []\n",
                        "\n",
                        "Step 2 - Entity Normalization:\n",
                        "  Normalized: []\n",
                        "\n",
                        " Note: 'diabete' was not recognized as a biomedical entity by SciSpaCy\n",
                        "  Reason: The typo is too different from known medical terms\n",
                        "  Solution: Use a question with a recognized entity, like 'diabetes'\n"
                    ]
                }
            ],
            "source": [
                "# Question with typo\n",
                "question = \"What treats diabete?\"  # Typo: \"diabete\"\n",
                "\n",
                "#  Extract entities\n",
                "state = {\"question\": question}\n",
                "state = question_agent.run(state)\n",
                "\n",
                "print(f\"Question: {question}\")\n",
                "print(f\"\\nStep 1 - Entity Extraction:\")\n",
                "print(f\"  Raw entities: {state['entities']}\")\n",
                "\n",
                "# S Normalize entities\n",
                "state = normalize_agent.run(state)\n",
                "\n",
                "print(f\"\\nStep 2 - Entity Normalization:\")\n",
                "print(f\"  Normalized: {state['normalized_entities']}\")\n",
                "\n",
                "if state['normalized_entities']:\n",
                "    print(f\"\\n Typo corrected: 'diabete' -> '{state['normalized_entities'][0]}'\")\n",
                "else:\n",
                "    print(\"\\n Note: 'diabete' was not recognized as a biomedical entity by SciSpaCy\")\n",
                "    print(\"  Reason: The typo is too different from known medical terms\")\n",
                "    print(\"  Solution: Use a question with a recognized entity, like 'diabetes'\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Understanding the Technology\n",
                "\n",
                "### SciSpaCy NER Model\n",
                "\n",
                "**Model**: `en_ner_bc5cdr_md`\n",
                "\n",
                "**Training Data**:\n",
                "- BC5CDR corpus (BioCreative V)\n",
                "- PubMed abstracts\n",
                "- Medical literature\n",
                "\n",
                "**Entity Types**:\n",
                "- **DISEASE**: diabetes, asthma, cancer, COVID-19\n",
                "- **CHEMICAL**: metformin, aspirin, insulin, acetaminophen\n",
                "\n",
                "**Why SciSpaCy?**\n",
                "- Specialized for biomedical text\n",
                "- Better than general NER for medical terms\n",
                "- Pre-trained (no training needed)\n",
                "\n",
                "### Fuzzy Matching with RapidFuzz\n",
                "\n",
                "**Algorithm**: Weighted Ratio (WRatio)\n",
                "\n",
                "**Canonical Vocabulary**: 182,775 biomedical entities\n",
                "\n",
                "**Similarity Threshold**: 72%\n",
                "\n",
                "**Why Fuzzy Matching?**\n",
                "- Handles typos\n",
                "- Handles variations\n",
                "- Fast (optimized C++ implementation)\n",
                "- Configurable threshold"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Interactive Testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Question: What is asthma?\n",
                        "============================================================\n",
                        "[QuestionAgent] Extracted raw entities: ['asthma']\n",
                        "\n",
                        "1. Extracted Entities:\n",
                        "   - asthma\n",
                        "[NormalizeAgent] Fuzzy-normalizing entities:\n",
                        "   Raw extracted entities: ['asthma']\n",
                        "   → 'asthma' → 'asthma' (score=100.0)\n",
                        "\n",
                        "2. Normalized Entities:\n",
                        "   - asthma\n",
                        "\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "def process_question(question):\n",
                "    \"\"\"Complete entity extraction and normalization\"\"\"\n",
                "    \n",
                "    print(f\"Question: {question}\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # Extract\n",
                "    state = {\"question\": question}\n",
                "    state = question_agent.run(state)\n",
                "    \n",
                "    print(f\"\\n1. Extracted Entities:\")\n",
                "    for ent in state['entities']:\n",
                "        print(f\"   - {ent}\")\n",
                "    \n",
                "    # Normalize\n",
                "    state = normalize_agent.run(state)\n",
                "    \n",
                "    print(f\"\\n2. Normalized Entities:\")\n",
                "    for ent in state['normalized_entities']:\n",
                "        print(f\"   - {ent}\")\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "\n",
                "# Try your own questions\n",
                "process_question(\"What is asthma?\")\n",
                "# process_question(\"Can asprin treat headaches?\")  # Typo: asprin\n",
                "# process_question(\"What causes diabetis?\")  # Typo: diabetis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Why This Matters for RAG\n",
                "\n",
                "### Without Entity Processing:\n",
                "```\n",
                "User: \"What treats diabete?\"\n",
                "Search: \"diabete\" (typo)\n",
                "Results: Poor (no exact match)\n",
                "Answer: Low quality\n",
                "```\n",
                "\n",
                "### With Entity Processing:\n",
                "```\n",
                "User: \"What treats diabete?\"\n",
                "Extract: [\"diabete\"]\n",
                "Normalize: [\"diabetes mellitus\"]\n",
                "Search: \"diabetes mellitus\" (correct)\n",
                "Results: Excellent\n",
                "Answer: High quality\n",
                "```\n",
                "\n",
                "**Impact**: Better retrieval - Better answers"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
